{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f953146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637a5cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "books_df = pd.read_json('20s_best_book.json')\n",
    "books = books_df[['no', 'ranking', 'bookname', 'authors', 'publisher', 'publication_year', 'isbn13']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4858c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_page_and_weight(isbn):\n",
    "    url = 'http://www.yes24.com/Product/Search?domain=BOOK&query={}'\n",
    "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "    try:\n",
    "        r = requests.get(url.format(isbn), headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        prd_info = soup.find('a', attrs={'class': 'gd_name'})\n",
    "        if prd_info is None:\n",
    "            return None, None\n",
    "\n",
    "        detail_url = 'http://www.yes24.com' + prd_info['href']\n",
    "        r = requests.get(detail_url, headers=headers, timeout=5)\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        prd_detail = soup.find('div', attrs={'id': 'infoset_specific'})\n",
    "        if prd_detail is None:\n",
    "            return None, None\n",
    "\n",
    "        prd_tr_list = prd_detail.find_all('tr')\n",
    "        for tr in prd_tr_list:\n",
    "            th = tr.find('th')\n",
    "            td = tr.find('td')\n",
    "            if th and th.get_text(strip=True) == '쪽수, 무게, 크기':\n",
    "                info_parts = [part.strip() for part in td.get_text(strip=True).split('|')]\n",
    "                page_cnt = int(''.join(filter(str.isdigit, info_parts[0]))) if len(info_parts) >= 1 else None\n",
    "                weight_info = info_parts[1] if len(info_parts) >= 2 else None\n",
    "                return page_cnt, weight_info\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"[예외 발생] ISBN {isbn}: {e}\")\n",
    "        return None, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69458610",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page_list = []\n",
    "weight_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf2278",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, isbn in enumerate(books['isbn13']):\n",
    "    print(f\"[{i+1}] ISBN {isbn} 처리 중...\")\n",
    "    page, weight = get_page_and_weight(isbn)\n",
    "    page_list.append(page)\n",
    "    weight_list.append(weight)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408c9d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "books['page_cnt'] = page_list\n",
    "books['weight_info'] = weight_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b994ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "books.head()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
